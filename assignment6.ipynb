{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ejohnson/.local/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import fastai\n",
    "\n",
    "from fastai.io import *\n",
    "\n",
    "from fastai.column_data import *\n",
    "from fastai.text import *\n",
    "\n",
    "import mygru\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning to generate Dickens-like text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "davidcopperfield.txt  \u001b[0m\u001b[01;34mmodels\u001b[0m/  \u001b[01;34mtmp\u001b[0m/  \u001b[01;34mtrn\u001b[0m/  \u001b[01;34mval\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "from torchtext import vocab, data\n",
    "\n",
    "from fastai.nlp import *\n",
    "from fastai.lm_rnn import *\n",
    "\n",
    "PATH=Path('../data/dickens/')\n",
    "\n",
    "TRN_PATH = 'trn'\n",
    "VAL_PATH = 'val'\n",
    "TRN = PATH / TRN_PATH\n",
    "VAL = PATH / VAL_PATH\n",
    "\n",
    "%ls {PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44, 53, 1, 1494913)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT = data.Field(lower=True, tokenize=list)\n",
    "bs=2048; bptt=16; n_fac=42; n_hidden=256\n",
    "\n",
    "FILES = dict(train=TRN_PATH, validation=VAL_PATH, test=VAL_PATH)\n",
    "md = LanguageModelData.from_text_files(PATH, TEXT, **FILES, bs=bs, bptt=bptt, min_freq=3)\n",
    "\n",
    "len(md.trn_dl), md.nt, len(md.trn_ds), len(md.trn_ds[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru = mygru.MyGRU\n",
    "#gru = nn.GRU\n",
    "\n",
    "class CharSequence(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac, bs, nl):\n",
    "        super().__init__()\n",
    "        self.vocab_size,self.nl = vocab_size,nl\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.dropout = nn.Dropout(.1)\n",
    "        self.rnn = gru(n_fac, n_hidden, nl, dropout=0.0)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        self.init_hidden(bs)\n",
    "        \n",
    "    def forward(self, cs):\n",
    "        bs = cs[0].size(0)\n",
    "        if self.h[0].size(1) != bs: self.init_hidden(bs)\n",
    "        outp,h = self.rnn(self.dropout(self.e(cs)), self.h)\n",
    "        self.h = repackage_var(h)\n",
    "        return F.log_softmax(self.l_out(outp), dim=-1).view(-1, self.vocab_size)\n",
    "    \n",
    "    def init_hidden(self, bs):\n",
    "        self.h = V(torch.zeros(self.nl, bs, n_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fc3e5dff0ba4f63b0afd8f91deab1bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=31), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   \n",
      "    0      2.724434   2.515666  \n",
      "    1      2.530044   2.403224  \n",
      "    2      2.452712   2.383669  \n",
      "    3      2.408054   2.337248  \n",
      "    4      2.367373   2.309155  \n",
      "    5      2.339531   2.295352  \n",
      "    6      2.32204    2.291577  \n",
      "    7      2.30302    2.254059  \n",
      "    8      2.276722   2.217139  \n",
      "    9      2.248484   2.18665   \n",
      "    10     2.224118   2.169542  \n",
      "    11     2.211261   2.153002  \n",
      "    12     2.199884   2.157842  \n",
      "    13     2.191732   2.153031  \n",
      "    14     2.187825   2.148998  \n",
      "    15     2.184781   2.139559  \n",
      "    16     2.173614   2.123683  \n",
      "    17     2.164717   2.111198  \n",
      "    18     2.15509    2.104103  \n",
      "    19     2.145673   2.098667  \n",
      "    20     2.139509   2.089549  \n",
      "    21     2.133651   2.094017  \n",
      "    22     2.129979   2.081859  \n",
      "    23     2.127539   2.084422  \n",
      "    24     2.123623   2.07667   \n",
      "    25     2.121288   2.069183  \n",
      "    26     2.11953    2.078462  \n",
      "    27     2.11682    2.068764  \n",
      " 25%|██▌       | 11/44 [00:01<00:04,  7.85it/s, loss=2.12]"
     ]
    }
   ],
   "source": [
    "char = CharSequence(md.nt, n_fac, n_hidden, 1)\n",
    "if torch.cuda.is_available():\n",
    "    char = char.cuda()\n",
    "m = BasicModel(char)\n",
    "learner = RNN_Learner(md, m, opt_fn=optim.Adam, crit=F.nll_loss)\n",
    "\n",
    "#minimum_learning_rate_divisor = 1200\n",
    "#percent_after_triangle_cycle = 15\n",
    "#max_momentum=.97\n",
    "#min_momentum=.85\n",
    "#learner.fit(1e-2, 1, cycle_len=72, \n",
    "#           use_clr_beta=(minimum_learning_rate_divisor, \n",
    "#                         percent_after_triangle_cycle, \n",
    "#                         max_momentum, \n",
    "#                         min_momentum),\n",
    "#                         wds=1e-5)\n",
    "learner.fit(2e-2, 5, cycle_mult=2, cycle_len=1, \n",
    "           wds=1e-5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    device = None if torch.cuda.is_available() else -1\n",
    "    idxs = TEXT.numericalize(inp, device=device, train=False)\n",
    "    p = learner.model(VV(idxs.transpose(0,1)))\n",
    "    r = torch.multinomial(p[-1].exp(), 1)\n",
    "    return TEXT.vocab.itos[to_np(r)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'k'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('for thos')\n",
    "#TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next_n(inp, n):\n",
    "    res = inp\n",
    "    for i in range(n):\n",
    "        c = get_next(inp)\n",
    "        res += c\n",
    "        inp = inp[1:]+c\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fourscore and seven years agoldithig ayh hainksudng wion, stedonever.---at oadnede ly soult thicellteacce istouk awidthay drionly ad’ ourng theghing theen, rve achis ind ind eamer pes in as ittan isco rreutthake isos,  thave torr hegly, the ‘ile, saicasy wayt han  moreand aidg tiony uanl, da sthe min ag noter for mry seer erere--retad bouthimot ento wet toher and lwing iored loy the for angeupinth. g ivelly tor  mond barme of\n"
     ]
    }
   ],
   "source": [
    "print(get_next_n('fourscore and seven years ago', 400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "nav_menu": {},
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "216px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
